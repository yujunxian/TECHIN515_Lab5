{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb8015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from azureml.core import Workspace, Dataset, Run\n",
    "\n",
    "# Define constants\n",
    "GESTURE_CLASSES = [\"O\", \"V\"] # Adjust based on your data\n",
    "SEQUENCE_LENGTH = 100  # Adjust based on your data\n",
    "MODEL_SAVE_PATH = \"wand_model.h5\"\n",
    "\n",
    "def load_data_from_directory(directory):\n",
    "    \"\"\"Load gesture sequences from CSV files organized in subdirectories by class.\"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, class_name in enumerate(GESTURE_CLASSES):\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "\n",
    "        if not os.path.isdir(class_dir):\n",
    "            print(f\"Skipping missing class directory: {class_dir}\")\n",
    "            continue\n",
    "\n",
    "        for file_name in os.listdir(class_dir):\n",
    "            if file_name.endswith('.csv'):\n",
    "                file_path = os.path.join(class_dir, file_name)\n",
    "\n",
    "                try:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    if not {'x', 'y', 'z'}.issubset(df.columns):\n",
    "                        print(f\"Skipping malformed CSV (missing columns): {file_name}\")\n",
    "                        continue\n",
    "\n",
    "                    sequence = df[['x', 'y', 'z']].values.tolist()\n",
    "\n",
    "                    if len(sequence) >= SEQUENCE_LENGTH:\n",
    "                        features.append(sequence[:SEQUENCE_LENGTH])\n",
    "                        labels.append(idx)\n",
    "                    elif len(sequence) > 10:  # ignore very short sequences\n",
    "                        padded = sequence + [[0, 0, 0]] * (SEQUENCE_LENGTH - len(sequence))\n",
    "                        features.append(padded)\n",
    "                        labels.append(idx)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_name}: {e}\")\n",
    "\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "\n",
    "def preprocess_data(features, labels):\n",
    "    \"\"\"Preprocess the data: reshape, normalize, and split into train/test sets.\"\"\"\n",
    "    n_samples = features.shape[0]\n",
    "    features_flat = features.reshape(n_samples, -1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    features_normalized = scaler.fit_transform(features_flat)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features_normalized, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    \"\"\"Build a neural network model for gesture classification.\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(input_shape,)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation accuracy/loss.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['loss'], label='Training Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # Detect if we're running in AzureML job context or not\n",
    "    run = Run.get_context()\n",
    "\n",
    "    if hasattr(run, \"experiment\"):\n",
    "        # We're in an AzureML job\n",
    "        ws = run.experiment.workspace\n",
    "    else:\n",
    "        # We're running locally (e.g., in JupyterLab)\n",
    "        ws = Workspace.from_config()  # assumes config.json is present or you're in a bound environment\n",
    "\n",
    "    # Proceed as normal with dataset\n",
    "    dataset = Dataset.File.from_files(path=(ws.get_default_datastore(), 'UI/2025-05-25_062316_UTC/data/**')) # Find the relative path in your own datastore\n",
    "\n",
    "    mount_context = dataset.mount(\"data\")\n",
    "    mount_context.start()\n",
    "\n",
    "    try:\n",
    "        print(\"Loading data from mounted dataset...\")\n",
    "        features, labels = load_data_from_directory(\"data\")\n",
    "\n",
    "        if len(features) == 0:\n",
    "            print(\"No data found. Please check your data directory.\")\n",
    "            return\n",
    "\n",
    "        print(f\"Loaded {len(features)} samples across {len(GESTURE_CLASSES)} classes\")\n",
    "\n",
    "        X_train, X_test, y_train, y_test = preprocess_data(features, labels)\n",
    "        input_shape = X_train.shape[1]\n",
    "        model = build_model(input_shape, len(GESTURE_CLASSES))\n",
    "\n",
    "        print(\"Training model...\")\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=10,\n",
    "                    restore_best_weights=True\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(\"Evaluating model...\")\n",
    "        test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "        print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "        run.log(\"Test Accuracy\", test_acc)\n",
    "        run.log(\"Test Loss\", test_loss)\n",
    "\n",
    "        plot_training_history(history)\n",
    "        model.save(MODEL_SAVE_PATH)\n",
    "        print(f\"Model saved to {MODEL_SAVE_PATH}\")\n",
    "\n",
    "    finally:\n",
    "        mount_context.stop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
